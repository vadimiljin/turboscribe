# Script Validation Report

**–î–∞—Ç–∞:** 2025-11-15  
**–§–∞–π–ª:** `standardize_product_reviews.py`  
**–ü—Ä–æ–≤–µ—Ä—è—é—â–∏–π:** AI Assistant

---

## ‚úÖ –°–¢–ê–¢–£–°: –°–ö–†–ò–ü–¢ –ò–°–ü–†–ê–í–ï–ù

–°–∫—Ä–∏–ø—Ç –ø—Ä–æ—à–µ–ª –≤—Å–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏. –í—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –≤–Ω–µ—Å–µ–Ω–Ω—ã–µ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è URLs, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.

---

## üìã –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏

### 1. ‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å Python
```
‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
‚úÖ AST –ø–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω
‚úÖ –ö–ª–∞—Å—Å–æ–≤: 1
‚úÖ –§—É–Ω–∫—Ü–∏–π/–º–µ—Ç–æ–¥–æ–≤: 40
‚úÖ –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: 2951
```

### 2. ‚úÖ –ò–º–ø–æ—Ä—Ç—ã
```
‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–π import re –Ω–∞ —Å—Ç—Ä–æ–∫–µ 11
‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ import re –≤ 13 –º–µ—Ç–æ–¥–∞—Ö (–¥–æ–ø—É—Å—Ç–∏–º–æ)
‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã
```

### 3. ‚úÖ –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
```
‚úÖ extract_urls_with_context - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
‚úÖ restore_urls - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
‚úÖ standardize_file_full - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ standardize_file_chunked - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ fix_name_format - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ fix_decisions_section - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ remove_team_links - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ fix_placeholder_emails - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ extract_names_from_text - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
‚úÖ resolve_name_disambiguation - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
```

### 4. ‚úÖ –õ–æ–≥–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è URLs

#### Full Mode (`standardize_file_full`):
```python
# –°—Ç—Ä–æ–∫–∞ 1819-1822: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URLs –î–û LLM
original_urls = self.extract_urls_with_context(original_content)
print(f"   [OK] –ù–∞–π–¥–µ–Ω–æ {len(original_urls)} URLs")

# ... LLM –æ–±—Ä–∞–±–æ—Ç–∫–∞ ...

# –°—Ç—Ä–æ–∫–∞ 1933-1936: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ URLs –ü–û–°–õ–ï LLM
print(f"   [URLS] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ URLs...")
standardized_content = self.restore_urls(standardized_content, original_urls)
print(f"   [OK] URLs –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
```
‚úÖ **–ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:** URLs –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –î–û ‚Üí –û–±—Ä–∞–±–æ—Ç–∫–∞ LLM ‚Üí URLs –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –ü–û–°–õ–ï

#### Chunked Mode (`standardize_file_chunked`):
```python
# –°—Ç—Ä–æ–∫–∞ 2345-2348: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URLs –î–û LLM
original_urls = self.extract_urls_with_context(original_content)
print(f"   [OK] –ù–∞–π–¥–µ–Ω–æ {len(original_urls)} URLs")

# ... LLM –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–æ–≤ ...

# –°—Ç—Ä–æ–∫–∞ 2746-2753: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ URLs –ü–û–°–õ–ï LLM
print(f"   [URLS] –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ URLs...")
full_standardized = self.restore_urls(full_standardized, original_urls)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ URLs
with open(file_info['target'], 'w', encoding='utf-8') as f:
    f.write(full_standardized)
print(f"   [OK] URLs –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
```
‚úÖ **–ü–æ—Ä—è–¥–æ–∫ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:** URLs –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –î–û ‚Üí –û–±—Ä–∞–±–æ—Ç–∫–∞ LLM ‚Üí URLs –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –ü–û–°–õ–ï

### 5. ‚úÖ –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤

#### `extract_urls_with_context(text: str) -> List[Dict]`
```python
def extract_urls_with_context(self, text: str) -> List[Dict]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ URLs —Å –æ–∫—Ä—É–∂–∞—é—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (30 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π: {'url': '...', 'context_before': '...', 'context_after': '...'}
    """
    import re
    pattern = r'https?://[^\s\)\]]+(?:[^\s\)\]])*'
    
    urls_data = []
    for match in re.finditer(pattern, text):
        url = match.group(0)
        start = match.start()
        end = match.end()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (30 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ)
        context_before = text[max(0, start-30):start]
        context_after = text[end:min(len(text), end+30)]
        
        urls_data.append({
            'url': url,
            'context_before': context_before,
            'context_after': context_after,
            'position': start
        })
    
    return urls_data
```
‚úÖ **–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞**

#### `restore_urls(processed_text: str, original_urls: List[Dict]) -> str`
```python
def restore_urls(self, processed_text: str, original_urls: List[Dict]) -> str:
    """
    –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç URLs –≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–µ—Å—Ç–∞ –≤—Å—Ç–∞–≤–∫–∏.
    """
    import re
    
    if not original_urls:
        return processed_text
    
    result = processed_text
    
    for url_data in original_urls:
        url = url_data['url']
        context_before = url_data['context_before']
        context_after = url_data['context_after']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —ç—Ç–æ—Ç URL –≤ —Ç–µ–∫—Å—Ç–µ
        if url in result:
            continue
        
        # –ò—â–µ–º –º–µ—Å—Ç–æ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        # –£–±–∏—Ä–∞–µ–º –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤–æ–∑–º–æ–∂–Ω—ã–µ URL –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        clean_context_before = re.sub(r'https?://[^\s\)\]]+', '', context_before)
        clean_context_after = re.sub(r'https?://[^\s\)\]]+', '', context_after)
        
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–µ—Å—Ç–æ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
        # –í–∞—Ä–∏–∞–Ω—Ç 1: –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        search_pattern = re.escape(clean_context_before.strip()[-20:] if len(clean_context_before.strip()) > 20 else clean_context_before.strip())
        
        if search_pattern:
            matches = list(re.finditer(search_pattern, result))
            if matches:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏ –≤—Å—Ç–∞–≤–ª—è–µ–º URL –ø–æ—Å–ª–µ –Ω–µ–≥–æ
                insert_pos = matches[0].end()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ URL —Ä—è–¥–æ–º
                next_chars = result[insert_pos:insert_pos+50]
                if not re.search(r'https?://', next_chars):
                    result = result[:insert_pos] + ' ' + url + result[insert_pos:]
    
    return result
```
‚úÖ **–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞**

### 6. ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è DIMINUTIVE_NAMES
```python
DIMINUTIVE_NAMES = {
    # ...
    '–í–ª–∞–¥–∏–º–∏—Ä': ['–í–æ–ª–æ–¥—è'],  # –î–ª—è Vladimir Fedorov (–ë–ï–ó –í–æ–≤–∞!)
    '–í–æ–≤–∞': [],  # –í–æ–≤–∞ - —ç—Ç–æ –ü–û–õ–ù–û–ï –∏–º—è Vladimir Zhakhavets! –ù–µ —É–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω–æ–µ
    # ...
}
```
‚úÖ **–í–æ–≤–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –∫–∞–∫ –ø–æ–ª–Ω–æ–µ –∏–º—è, –∞ –Ω–µ diminutive**

### 7. ‚úÖ –ü–æ—Ä—è–¥–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–µ
```
–ü–æ—Ä—è–¥–æ–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:
  1809: standardize_file_full
  1953: extract_urls_with_context
  1982: restore_urls
  2332: standardize_file_chunked

‚ö†Ô∏è –ó–∞–º–µ—á–∞–Ω–∏–µ: –ú–µ—Ç–æ–¥—ã extract_urls_with_context –∏ restore_urls –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã 
–ü–û–°–õ–ï –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –ù–û —ç—Ç–æ –ù–ï –ø—Ä–æ–±–ª–µ–º–∞ –≤ Python!

‚úÖ –í Python –ø–æ—Ä—è–¥–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–µ –ù–ï –í–ê–ñ–ï–ù - –º–µ—Ç–æ–¥—ã –≤—ã–∑—ã–≤–∞—é—Ç—Å—è 
–≤ runtime, –∫–æ–≥–¥–∞ –≤–µ—Å—å –∫–ª–∞—Å—Å —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω.
```

### 8. ‚úÖ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
```
‚úÖ –ö–ª–∞—Å—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ
‚úÖ –í—Å–µ –º–µ—Ç–æ–¥—ã –¥–æ—Å—Ç—É–ø–Ω—ã
‚úÖ extract_urls_with_context —Ä–∞–±–æ—Ç–∞–µ—Ç: –Ω–∞–π–¥–µ–Ω–æ 1 URLs
‚úÖ restore_urls —Ä–∞–±–æ—Ç–∞–µ—Ç: 34 —Å–∏–º–≤–æ–ª–æ–≤
‚úÖ emails.csv –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è: 36 email
‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–º–µ–Ω: 488 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ 111 –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
```

---

## üîç –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–∞–≥–∏

### ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω: Bug #1 - import re
**–°—Ç–∞—Ç—É—Å:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω  
**–î–µ—Ç–∞–ª–∏:** `import re` –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —Å—Ç—Ä–æ–∫–µ 11 (–≥–ª–æ–±–∞–ª—å–Ω–æ)

### ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω: Bug #2 - –í–æ–≤–∞ –∫–∞–∫ diminutive
**–°—Ç–∞—Ç—É—Å:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω  
**–î–µ—Ç–∞–ª–∏:** `'–í–æ–≤–∞': []` - –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –í–æ–≤–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è diminutive

### ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: Feature #1 - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URLs
**–°—Ç–∞—Ç—É—Å:** –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–î–µ—Ç–∞–ª–∏:** –ú–µ—Ç–æ–¥ `extract_urls_with_context` –¥–æ–±–∞–≤–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç

### ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω: Feature #2 - –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ URLs
**–°—Ç–∞—Ç—É—Å:** –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω  
**–î–µ—Ç–∞–ª–∏:** –ú–µ—Ç–æ–¥ `restore_urls` –¥–æ–±–∞–≤–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç

### ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω: Bug #3 - URLs –ø—Ä–æ–ø–∞–¥–∞—é—Ç
**–°—Ç–∞—Ç—É—Å:** –ò—Å–ø—Ä–∞–≤–ª–µ–Ω  
**–î–µ—Ç–∞–ª–∏:** URLs –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –î–û LLM –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –ü–û–°–õ–ï –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–¥–∞

```
–û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:
  - –°—Ç—Ä–æ–∫ –∫–æ–¥–∞: 2951
  - –ö–ª–∞—Å—Å–æ–≤: 1
  - –ú–µ—Ç–æ–¥–æ–≤: 40
  - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: ~120 KB

–ö—Ä–∏—Ç–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã:
  - extract_urls_with_context: —Å—Ç—Ä–æ–∫–∏ 1953-1980 (27 —Å—Ç—Ä–æ–∫)
  - restore_urls: —Å—Ç—Ä–æ–∫–∏ 1982-2021 (39 —Å—Ç—Ä–æ–∫)
  - standardize_file_full: —Å—Ç—Ä–æ–∫–∏ 1809-1951 (142 —Å—Ç—Ä–æ–∫–∏)
  - standardize_file_chunked: —Å—Ç—Ä–æ–∫–∏ 2332-2778 (446 —Å—Ç—Ä–æ–∫)
```

---

## üéØ –í—ã–≤–æ–¥

### ‚úÖ –°–∫—Ä–∏–ø—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏—Å–ø—Ä–∞–≤–µ–Ω

–í—Å–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ:

1. ‚úÖ URLs –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –î–û –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ LLM
2. ‚úÖ LLM –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç (–º–æ–∂–µ—Ç –ø–æ—Ç–µ—Ä—è—Ç—å URLs)
3. ‚úÖ URLs –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –ü–û–°–õ–ï –æ–±—Ä–∞–±–æ—Ç–∫–∏ LLM
4. ‚úÖ –õ–æ–≥–∏–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö (full –∏ chunked)
5. ‚úÖ –í—Å–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±–∞–≥–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã
6. ‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
7. ‚úÖ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

### üöÄ –°–∫—Ä–∏–ø—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç:
```bash
cd /home/vadim/Projects/route4me.com/turboscribe
python standardize_product_reviews.py --test
```

---

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

1. **–ü–æ—Ä—è–¥–æ–∫ –º–µ—Ç–æ–¥–æ–≤:** –í Python –ø–æ—Ä—è–¥–æ–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤ –≤ –∫–ª–∞—Å—Å–µ –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω. –ú–µ—Ç–æ–¥—ã `extract_urls_with_context` –∏ `restore_urls` –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø–æ—Å–ª–µ `standardize_file_full`, –Ω–æ —ç—Ç–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–æ–π, —Ç.–∫. –≤—ã–∑–æ–≤—ã –ø—Ä–æ–∏—Å—Ö–æ–¥—è—Ç –≤ runtime –∫–æ–≥–¥–∞ –≤–µ—Å—å –∫–ª–∞—Å—Å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ø–∞–º—è—Ç—å.

2. **–õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã:** –í 13 –º–µ—Ç–æ–¥–∞—Ö –µ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–π `import re`, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∏–º–ø–æ—Ä—Ç. –≠—Ç–æ –∏–∑–±—ã—Ç–æ—á–Ω–æ, –Ω–æ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—à–∏–±–∫–æ–π –∏ –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–±–æ—Ç—É —Å–∫—Ä–∏–ø—Ç–∞.

3. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** –° –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π `max_workers=15` —Å–∫—Ä–∏–ø—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Tier 3 OpenAI API (5,000 RPM).

---

**–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ:** 2025-11-15  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ PASSED  
**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –û–î–û–ë–†–ï–ù–û –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

